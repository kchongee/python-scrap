<a name="readme-top"></a>

# Web Scraping

<!-- Configuration -->
## Configuration
step 1: install python version 3, https://www.python.org/downloads/ (add to PATH)

step 2: create virtual environment
```python -m venv venv```

step 3: activate virtual environment
```source venv/Scripts/activate```

step 4: install required python packages/libraries 
```pip install -r requirements.txt``` to install all the packages written in the requirements.txt

step 5: run web scraping script
```python [filename].py```


### Note
Run following command:
- ```python --version``` can check whether python is installed
- ```which python``` to check which virtual environment was using
- ```deactivate``` to leave current virtual environment
- ```which python``` to check which virtual environment was using
- ```pip install [packages]==[version]``` to install desire packages in desire version
- ```pip freeze > requirements.txt``` to write all the packages installed in virtual environment into requirements.txt
- virtual environment here similar to project dependencies, pip similar to composer in php, TLDR: venv = composer + phpenv

  
<p align="right">(<a href="#readme-top">back to top</a>)</p>
